{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL IMPORTS\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import numpy as np \n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data\n",
    "\n",
    "### Aviation data from: https://www.transtats.bts.gov/Fields.asp\n",
    "- Select `Download` under `Data Tools`\n",
    "- Filter to `Year` you would like\n",
    "- Select these additiona columns:\n",
    "  - \"Passengers\"   \n",
    "  - \"OrigonCityName\"\n",
    "  - \"OriginState\"\n",
    "  - \"OriginStateFips\"\n",
    "  - \"DestCityName\"\n",
    "  - \"DestState\"\n",
    "  - \"DestStateFips\"\n",
    "  - \"Month\"\n",
    "- Select `Download`\n",
    "- Rename file and move to wrkdir\n",
    "\n",
    "### Airport Directory Data from: https://www.faa.gov/airports/airport_safety/airportdata_5010/ \n",
    "\n",
    "- Used to Map airport to county name\n",
    "- Many manual updates required, see update notes at end of notebook\n",
    "- There is a cleaned version of this file in the repo, but to get your own:\n",
    "  - scroll down to `Location(s) Selection Form`\n",
    "  - Select `Submit`\n",
    "  - Go to downloads\n",
    "- For a new Download, you will have to update the airport codes as shown in the notes at the bottom  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:\n",
    "\n",
    "- AK: n Small aerodromes are not mapped to proper IATA code, n depends on min_pax filter\n",
    "- FL: Fort Jefferson is federal land sans county\n",
    "- PR: No Counties\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILL THESE OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the year of the data you downloaded (used for timestamp)\n",
    "year = \"2019\"\n",
    "\n",
    "# Filter by minimum number of pax per month\n",
    "min_pax = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVIATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aviation Data\n",
    "aviation_fn = \"UScarrier_2019_all_months.csv\"\n",
    "wrkdir = os.getcwd()\n",
    "\n",
    "df_full = pd.read_csv(f\"{wrkdir}/{aviation_fn}\", sep=\",\", converters={'PASSENGERS': lambda x: int(float(x))},engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete phantom column\n",
    "df_full = df_full[df_full.columns.drop(list(df_full.filter(regex='Unnamed')))]\n",
    "\n",
    "# Delete rows with zero pax\n",
    "df = df_full[df_full['PASSENGERS'] > min_pax] \n",
    "\n",
    "# sort by month\n",
    "df = df.sort_values('MONTH').reset_index(drop=True)\n",
    "\n",
    "#Drop Saipan and local VI flights\n",
    "df =df[df[\"ORIGIN_STATE_ABR\"] != \"TT\"]\n",
    "df =df[df[\"ORIGIN_STATE_ABR\"] != \"VI\"]\n",
    "\n",
    "#Delete ISN WIlliston Airfield (closed October 10, 2019)\n",
    "df =df[df[\"ORIGIN\"] != \"ISN\"]\n",
    "df =df[df[\"DEST\"] != \"ISN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For lambda function\n",
    "def timestamp(x, year):\n",
    "    DD = \"01\"    \n",
    "    MM = str(x)\n",
    "    ts = f'{year}-{MM}-{DD}'\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add timestamp\n",
    "# YYYY-MM-DD\n",
    "df[\"TIMESTAMP\"] = df.MONTH.apply(lambda x: timestamp(x, year))\n",
    "\n",
    "# Split to just city name\n",
    "df[\"ORIGIN_CITY\"] = df.ORIGIN_CITY_NAME.apply(lambda x: x.split(\",\")[0])\n",
    "df[\"DEST_CITY\"] = df.DEST_CITY_NAME.apply(lambda x: x.split(\",\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIRPORT FACILITY DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Airport Facilities Directory data to get county name\n",
    "afd_fn = f\"{wrkdir}/airportFD.txt\"\n",
    "df_afd = pd.read_csv(afd_fn, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build county dictionary\n",
    "df_afd_county = pd.DataFrame(df_afd, columns = ['LocationID', 'County'])\n",
    "county_dict = df_afd_county.set_index('LocationID').to_dict()\n",
    "county_d = county_dict[\"County\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester for Airport to County\n",
    "tester = [\"CAK\", \"AUS\", \"SAN\", \"NUW\", \"DLF\", \"LKE\", \"RBH\"]\n",
    "for test in tester:\n",
    "    print(f'{test} is in {county_d[test]} County')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COUNTY FIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_fn = f\"{wrkdir}/county_to_fips.csv\"\n",
    "df_fips = pd.read_csv(fips_fn , sep=\",\", converters={\"FIPS County Code\": lambda x: str(x)},engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build county dictionary\n",
    "df_fips = pd.DataFrame(df_fips, columns = ['FIPS County Code', 'County Name'])\n",
    "fips_dict = df_fips.set_index('County Name').to_dict()\n",
    "fips_d = fips_dict[\"FIPS County Code\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UPDATE DF AND WRITE TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD Counties for origin and destination\n",
    "df_county = df.copy()\n",
    "df_county[\"ORIGIN_COUNTY\"] = df.ORIGIN.apply(lambda x: county_d.get(x, np.NaN))\n",
    "df_county[\"DEST_COUNTY\"] = df.DEST.apply(lambda x: county_d.get(x, np.NaN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD County FIPS for origin and destination\n",
    "df_fin = df_county.copy()\n",
    "df_fin[\"ORIGIN_COUNTY_FIPS\"] = df_fin.ORIGIN_COUNTY.apply(lambda x: fips_d.get(x, np.NaN))\n",
    "df_fin[\"DEST_COUNTY_FIPS\"] = df_fin.DEST_COUNTY.apply(lambda x: fips_d.get(x, np.NaN))\n",
    "\n",
    "# Replace #NAME? with NaN (for Puerto Rico)\n",
    "df_fin = df_fin.replace('#NAME?',np.NaN)\n",
    "df_fin = df_fin.replace('#NAME?',np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match capitalization format\n",
    "def cap_it(x):\n",
    "    temp = str(x).split()\n",
    "    tt= \"\"\n",
    "    for t in temp:\n",
    "        tt = tt + \" \" + t.capitalize()\n",
    "        \n",
    "    return tt.lstrip()\n",
    "\n",
    "df_fin[\"ORIGIN_COUNTY\"]=df_fin[\"ORIGIN_COUNTY\"].apply(lambda x: cap_it(x))\n",
    "df_fin[\"DEST_COUNTY\"]=df_fin[\"DEST_COUNTY\"].apply(lambda x: cap_it(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase and reorder the columns\n",
    "col_up = [\"TIMESTAMP\",\"ORIGIN\", \"ORIGIN_CITY\", \"ORIGIN_STATE_ABR\", \"ORIGIN_COUNTY\", \"ORIGIN_COUNTY_FIPS\",\n",
    "           \"DEST\",   \"DEST_CITY\",   \"DEST_STATE_ABR\",   \"DEST_COUNTY\",   \"DEST_COUNTY_FIPS\",\"PASSENGERS\"]\n",
    "\n",
    "col_low = [x.lower() for x in col_up]\n",
    "df_fin.columns = [x.lower() for x in df_fin.columns]\n",
    "df_fin =df_fin[col_low]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "df_fin.to_csv(fr'{wrkdir}/airport_pax_traffic_year={year}_min_pax={min_pax}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WORKS BUT NOT USED: APIs for FIPS Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fips(icao):\n",
    "    \n",
    "    # REF: https://positionstack.com/quickstart, file: API_key.txt\n",
    "    # position stack for lat/long of Airport ICAO\n",
    "    base = 'http://api.positionstack.com/v1/forward'\n",
    "    #key = 'API KEY HERE'\n",
    "    icao_t = icao\n",
    "    end = \" Airport\"\n",
    "    query = icao_t + end\n",
    "    country =\"US\"\n",
    "    output = 'json'\n",
    "    limit = 1\n",
    "    search_latlong = f'{base}?access_key={key}&query={query}&country={country}&output={output}&limit={limit}'\n",
    "\n",
    "    resp_latlong = requests.get(search_latlong)\n",
    "    resp_json = json.loads(resp_latlong.text)\n",
    "\n",
    "    lat = resp_json[\"data\"][0][\"latitude\"]\n",
    "    lon = resp_json[\"data\"][0][\"longitude\"]\n",
    "    \n",
    "    # From FCC, get FIPS county data\n",
    "    base_fcc = \"https://geo.fcc.gov/api/census/area?\"\n",
    "    search_fcc = f'{base_fcc}lat={lat}&lon={lon}&format=json'\n",
    "    \n",
    "    response_fcc = requests.get(search_fcc)\n",
    "    resp_fcc = json.loads(response_fcc.text)\n",
    "    \n",
    "    county_name = resp_fcc['results'][0]['county_name']\n",
    "    county_fips = resp_fcc['results'][0]['county_fips']\n",
    "    \n",
    "    icao_data = [county_name, county_fips]\n",
    "        \n",
    "    return icao_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Aviation data df to create list(df.series)\n",
    "d=set(df_fin.DEST.to_list())\n",
    "o=set(df_fin.ORIGIN.to_list())\n",
    "icaos = list(d.union(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_icaos = {}\n",
    "for icao in icaos[:10]:\n",
    "    all_icaos[icao]= get_fips(icao)\n",
    "all_icaos    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOT NEEDED: Top 50 Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 50 cities by population\n",
    "top_50_fn = \"city_top50.csv\"\n",
    "df_top_50 = pd.read_csv(f\"{wrkdir}/{top_50_fn}\", sep=\",\")\n",
    "\n",
    "# Filter to Top 50 cities by population\n",
    "top_50_list = df_top_50.city.tolist()\n",
    "\n",
    "df_full[\"ORIGIN_CITY\"] = df_full.ORIGIN_CITY_NAME.apply(lambda x: city_name(x))\n",
    "df_full[\"DEST_CITY\"] = df_full.DEST_CITY_NAME.apply(lambda x: city_name(x))\n",
    "\n",
    "\n",
    "# Airport ID Lookup\n",
    "airport_ID_fn= \"L_AIRPORT_ID.csv\"\n",
    "airport_ID = pd.read_csv(f\"{wrkdir}/{airport_ID_fn}\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airport Facilities Dir NOTES:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### County name to FIPS:\n",
    "- Delete `.` after `ST`\n",
    "\n",
    "#### Updates to IATA vs ICAO in airportFD.txt:\n",
    "state, from, to\n",
    "\n",
    "- AK, RBH copy of 5Z9\n",
    "- AK KLW copy AKW\n",
    "- CA, TRK, TKF\n",
    "- CA, CLD, CRQ\n",
    "- CA, IZA, SQA\n",
    "- MT, FCA, GPI\n",
    "- AZ, AZA, IWA\n",
    "- AZ, SCF, SDL\n",
    "- AZ, NYL, YUM\n",
    "- AZ, 1Z1, DQS\n",
    "- AZ, AZC, AZ7\n",
    "- PR, VQS, JRV\n",
    "- PA, UNV, SCE\n",
    "- MA, added UBF copy of CQX\n",
    "- MA, added QMN copy of 1B9\n",
    "- MO, added BKG copy of BBG\n",
    "- GA, added QMA, copy of RYY\n",
    "- GA, added LIY copy of LHW\n",
    "- NC, JQF, USA\n",
    "- NC, AKH, NC1\n",
    "- NC,  added NC2\n",
    "- NV, BVU, BLD\n",
    "- NV, HSH copy of HND\n",
    "- NV, NV05,NV5\n",
    "- MI, SAW, MQT\n",
    "- WA, S60, KEH\n",
    "- WA, added LKE same as KEH\n",
    "- WA, ORS, ESD\n",
    "- WA, FHR, FRD\n",
    "- WA, W33, FBS\n",
    "- TX DNE copy of DFW\n",
    "- FL RQZ copy of HRT\n",
    "- FL, X44, MPB\n",
    "- FL RBN has no ICAO....Fort Jefferson Island off Key West\n",
    "- FL, DTS, DSI\n",
    "- NY, POU, DQK * added row\n",
    "- NY, 0B8, FID *\n",
    "- NY, VWK, 5B2 *\n",
    "- ND ISN: closed October 10, 2019\n",
    "- SC, HXD, HHH *\n",
    "- SC, SC1 added Beaufort MCAS \n",
    "- UT, UXR copy of UT25\n",
    "- NJ, added PCT copy 39N\n",
    "- NJ, added NJ1 copy 19N\n",
    "- NM, TSM copy SKX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand-jam mapping of ICAO to County code:\n",
    "\n",
    "w= df_res[df_res[\"DEST_COUNTY\"]==\"None\"]\n",
    "w.shape\n",
    "\n",
    "# Switch to Origin also\n",
    "w[\"DEST_STATE_ABR\"].unique()\n",
    "\n",
    "w[w[\"ORIGIN_STATE_ABR\"]==\"FL\"][\"ORIGIN\"].unique()\n",
    "\n",
    "w[w[\"DEST_STATE_ABR\"]==\"TN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Airports without County FIPS\n",
    "\n",
    "df_fin[df_fin[\"ORIGIN_COUNTY_FIPS\"]=='None'].shape\n",
    "\n",
    "d=df_fin[df_fin[\"ORIGIN_COUNTY\"]=='None'][df_fin[\"ORIGIN_STATE_ABR\"]==\"AK\"]\n",
    "d=df_fin[df_fin[\"ORIGIN_COUNTY\"]=='None'][df_fin[\"ORIGIN_STATE_ABR\"]==\"AK\"]\n",
    "\n",
    "s=d[\"ORIGIN\"]\n",
    "\n",
    "v=set(s)\n",
    "\n",
    "len(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
